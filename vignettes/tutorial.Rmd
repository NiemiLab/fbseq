---
title: "`fbseq` package tutorial"
author: Will Landau
bibliography: bibliography.bib
date: 2015
output: 
  rmarkdown::html_vignette:
    number_sections: true
    pandoc_args: [
      "+RTS", "-K64m",
      "-RTS"]
    toc: true
vignette: >
  \VignetteEngine{knitr::rmarkdown}
  \VignetteIndexEntry{`fbseq` package tutorial}
  \usepackage[utf8]{inputenc}
---

```{r}
library(fbseq)
library(methods)
```

# Introduction

The `fbseq` package fits a hierarchical model to RNA-seq data in (nearly) fully Bayesian fashion. Although it was originally designed to fit RNA-seq data, it can also be used to analyze count data with tens of thousands of response variables and only a handful of observations each.

Please read the model vignette first. An understanding of the underlying hierarchical model is important for understanding how to use this package

# Check your system.

You need to have at least R $\ge$ 3.2.0, along with the R packages `coda`, `ggplot2`, `methods`, `reshape2`, and `knitr`. All are available through the [Comprehensive R Archive Network (CRAN](https://cran.r-project.org/). With those requirements met, you can install `fbseq`, load it in an R session, create input, and analyze output. To actually run the underlying Markov chain Monte Carlo (MCMC) procedure, however, you need access to a machine with a [CUDA-enabled GPU](http://www.nvidia.com/object/cuda_home_new.html), along with the [`fbseqCUDA` package](https://github.com/wlandau/fbseqCUDA). `fbseqCUDA` is the internal engine of `fbseq`, and it is implemented in CUDA to provide necessary acceleration for the MCMC. `fbseq` and `fbseqCUDA` are kept separate for convenience. For example, you can set up input with `fbseq` and without `fbseqCUDA` on a low-end laptop, run the main algorithm remotely with both `fbseq` and `fbseqCUDA` on a CUDA-enabled [cloud computing enterprise](http://www.nvidia.com/object/gpu-cloud-computing-services.html) such as [Amazon Web Services](http://aws.amazon.com/ec2/instance-types/), and analyze the output locally with `fbseq` and without `fbseqCUDA`. See the `fbseqCUDA` installation vignette for more details.

# Install `fbseq` and then `fbseqCUDA`.

## Option 1: install directly from GitHub.

For this option, you need the `devtools` package, available from CRAN or GitHub. Just open R and run 

```{r, eval=F}
library(devtools)
install_github("wlandau/fbseq")
```
and then if you have CUDA,

```{r, eval=F}
install_github("wlandau/fbseqCUDA")
```

## Option 2: install from the source.

Open a command line program such as Terminal in Mac/Linux and enter the following commands.

```
git clone git@github.com:wlandau/fbseq.git
R CMD build fbseq
R CMD INSTALL fbseq_0.0.tar.gz
```

Note: you may have to replace `fbseq_0.0.tar.gz` by the name of whatever tarball comes out of `R CMD build`. 

You can install `fbseqCUDA` next, and the steps are analogous. However, you may have to modify the top of the `src/Makevars` file before running `R CMD build`. See the `fbseqCUDA` package vignette for more detailed installation instructions.


# Workflow overview

A typical workflow only requires a few lines of code. However, it requires an understanding of the S4 classes of this package. The steps are as follows.

## Create a `Scenario` object.

`Scenario` is an S4 class for storing the count data, design matrix, and instructions for calculating posterior probabilities of quantities of interest.

```{r}
str(new("Scenario"))
```

Type `help("Scenario-class")` for details about the slots. When you have these slots ready, use the ``Scenario`` function to create a ``Scenario`` object.

```{r, eval = F}
scenario = Scenario(counts = counts, design = design, contrasts = contrasts, bounds = bounds, propositions = propositions, supplement = supplement)
```

With the exception of `Chain` objects, arguments passed to `Scenario` need to be explicitly passed to their slots. For example,

```{r, eval = F}
scenario = Scenario(counts, design, contrasts, bounds, propositions, supplement)
```

would throw an error.



### Example scenario from @paschold

The package comes with a `Scenario` with data taken from @paschold. The data is from an RNA-sequencing (RNA-seq) data experiment on maize described in the paper.

```{r}
data(paschold)
head(paschold@counts)
```

Here, the genes are rows (response variables) and the columns are RNA-seq libraries (observations, samples of genetic material). Each count is the relative measure of the expression of a gene in a laboratory sample of genetic material. The observations are divided into 4 groups:

- `B73`: maize seedlings from an inbred corn population in Iowa.
- `Mo17`: seedlings from a different inbred corn population in Missouri. 
- `B73xMo17`: hybrid seedlings produced from pollenating `B73` corn plants with `Mo17` pollen. 
- `Mo17xB73`: hybrid seedlings produced from pollenating `Mo17` corn plants with `B73` pollen.

The goal of this scenario is to detect which genes satisfy which of following conditions.

|------------------------------------|----------|--------------------------------------------------| 
| high-parent heterosis, both hybrids |	$\qquad$ | all hybrid counts > `B73` and `Mo17` counts  | 
| low-parent heterosis, both hybrids  |	|  all hybrid counts < `B73` and `Mo17` counts  | 
| high-parent heterosis, `B73xMo17`   |	|  `B73xMo17` counts > `B73` and `Mo17` counts  | 
| low-parent heterosis, `B73xMo17`    |	|  `B73xMo17` counts < `B73` and `Mo17` counts  | 
| high-parent heterosis, `Mo17xB73`   |	|  `Mo17xB73` counts > `B73` and `Mo17` counts  | 
| low-parent heterosis, `Mo17xB73`    |	|  `Mo17xB73` counts < `B73` and `Mo17` counts  | 

To translate this problem into a `Scenario`, we use the design matrix,

```{r}
paschold@design
```

In words, the main effect parameters are $\beta_{\ell, g}$ for effect $\ell = 1, \ldots, L = 5$ and $g = 1, \ldots, G = 39656$, and they describe linear combinations of the libraries within a gene. In the following table, a logarithmic scale is used for the interpretations.

|------------------------------------|----------|--------------------------------------------------| 
| $\beta_{1, g}$  |	$\qquad$ | mean of `B73` and `Mo17`  | 
| $\beta_{2, g}$ |	|  half the difference between `Mo17` and the hybrids  | 
| $\beta_{3, g}$   |	| half the difference between `B73` and the hybrids  | 
|$\beta_{4, g}$   |	| difference between `B73xMo17` and `Mo17xB73` | 
|$\beta_{5, g}$   |	|  experimental block effect  | 

With these interpretations, the table of conditions becomes

|------------------------------------|----------|--------------------------------------------------| 
| high-parent heterosis, both hybrids |	$\qquad$ |  $\beta_{2, g} > 0$ and $\beta_{3, g} > 0$ | 
| low-parent heterosis, both hybrids  |	|   $-\beta_{2, g} > 0$ and $-\beta_{3, g} > 0$ | 
| high-parent heterosis, `B73xMo17`   |	|  $2\beta_{2, g} + \beta_{4, g} > 0$ and $2\beta_{3, g} + \beta_{4, g} > 0$  | 
| low-parent heterosis, `B73xMo17`    |	| $-2\beta_{2, g} - \beta_{4, g} > 0$ and $-2\beta_{3, g} - \beta_{4, g} > 0$ | 
| high-parent heterosis, `Mo17xB73`   |	|  $2\beta_{2, g} - \beta_{4, g} > 0$ and $2\beta_{3, g} - \beta_{4, g} > 0$  | 
| low-parent heterosis, `Mo17xB73`    |	| $-2\beta_{2, g} + \beta_{4, g} > 0$ and $-2\beta_{3, g} + \beta_{4, g} > 0$ | 

Each linear combination of the $\beta_{\ell, g}$'s is a contrast, and each row of the table is a logical proposition. We want a posterior probability for each proposition. Let $\text{I}(\cdot)$ be the indicator function, $m = 1, \ldots, M$ be an MCMC iteration (including "thinned" iterations, but not burnin/throwaway iterations), and $\beta_{\ell, g}^{(m)}$ be the MCMC sample of $\beta_{\ell, g}$ for iteration $m$. Then, the posterior probabilities of interest should be calculated as:

$$ \begin{align*}
P(\text{high-parent heterosis, both hybrids} \ | \ \text{data}) &\approx \frac{1}{M} \sum_{m = 1}^M \text{I}\left (\beta_{2, g}^{(m)} > 0 \text{ and } \beta_{3, g}^{(m)} > 0 \right ) \\
P(\text{low-parent heterosis, both hybrids}) \ | \ \text{data}) &\approx \frac{1}{M} \sum_{m = 1}^M \text{I}\left ( -\beta_{2, g}^{(m)} > 0 \text{ and } -\beta_{3, g}^{(m)} > 0 \right ) \\
P(\text{high-parent heterosis, B73xMo17}) \ | \ \text{data}) &\approx \frac{1}{M} \sum_{m = 1}^M \text{I}\left ( 2\beta_{2, g}^{(m)} + \beta_{4, g}^{(m)} > 0 \text{ and } 2\beta_{3, g}^{(m)} + \beta_{4, g}^{(m)} > 0 \right ) \\
P(\text{low-parent heterosis, B73xMo17}) \ | \ \text{data}) &\approx \frac{1}{M} \sum_{m = 1}^M \text{I}\left ( -2\beta_{2, g}^{(m)} - \beta_{4, g}^{(m)} > 0 \text{ and } -2\beta_{3, g}^{(m)} - \beta_{4, g}^{(m)} > 0 \right ) \\
P(\text{high-parent heterosis, Mo17xB73}) \ | \ \text{data}) &\approx \frac{1}{M} \sum_{m = 1}^M \text{I}\left ( 2\beta_{2, g}^{(m)} - \beta_{4, g}^{(m)} > 0 \text{ and } 2\beta_{3, g}^{(m)} - \beta_{4, g}^{(m)} > 0 \right ) \\
P(\text{low-parent heterosis, Mo17xB73}) \ | \ \text{data}) &\approx \frac{1}{M} \sum_{m = 1}^M \text{I}\left ( -2\beta_{2, g}^{(m)} + \beta_{4, g}^{(m)} > 0 \text{ and }-2\beta_{3, g}^{(m)} + \beta_{4, g}^{(m)} > 0 \right )
\end{align*} $$

To tell the package to calculate these posterior probabilities, be sure to make use of the `contrasts`, `bounds`, and `propositions` slots. The Paschold scenario has the 12 contrasts,

```{r}
paschold@contrasts
```

the lower bounds in the inequalities (all zero),

```{r}
paschold@bounds
```

and the 6 logical propositions we care about, expressed in terms of the indices of the contrasts above.

```{r}
paschold@propositions
```

When the MCMC is run with the `fbseq` function, the package will estimate, for each gene, the probability that each of the 6 propositions is true.

Note: every `Scenario` object has an optional `suppelement` slot with additional information about the scenario. In this case, `paschold@supplement` is an empty list.



### Example simulated scenario with `scenario_heterosis_model`

To simulate a heterosis scenario similar to that of @paschold, use the `scenario_heterosis_model` function. Count data are simulated from the model given fixed values for the hyperparameters. 

```{r}
s = scenario_heterosis_model(genes = 1000, libraries = 16)
head(s@counts)
s@design
s@contrasts
s@bounds
s@propositions
```


## (Optional) create a `Configs` object.
 
The `Configs` S4 class contains the practical MCMC configuration parameters, such as the number of Monte Carlo iterations and the length of burnin, and important details about model specification. All of them have default settings, so just for the sake of trying out the package, you should be able to get away with calling the `Configs` function with no arguments. For a full list of slots and their explanations, type `help("Configs-class")`.

However, for serious analyses, you may want to adjust the `iterations`, `burnin`, and `thin` slots to control the duration of the MCMC. `burinin` is the number of throwaway iterations at the beginning of the MCMC, `iterations` is the number of iterations for which parameter samples are actually returned to the user, and `thin` specifies the thinning interval.  The total number of MCMC iterations is `burnin + iterations * thin`, and all of the `iterations * thin` portion is used to calculate posterior means, mean squares, and posterior probabilities of interest specified in the `Scenario` object. If `thin` is > 1, not all parameter samples after burnin are returned to the user. For example, `thin` is 10, then after burnin, actual parameter samples are saved every 10th iteration.

You may also want to adjust the `Configs` slots that apply constraints on model parameters. The `parameter_sets_update` controls which sets of parameters to update during the MCMC. Parameter sets not specified in `parameter_sets_update` will be held constant, so this slot can be used to run an empirical Bayes analysis, for example. The `parameter_sets_return`, `genes_return`, `libraries_return` (currently moot because there are no library-specific parameters other than the epsilons), `genes_return_epsilon`, and `libraries_return_epsilon` slots control which Monte Carlo parameter samples to return to the user.

The `samplers` slot, in principle, allows the user to choose the MCMC algorithm to use: slice sampling, Metropolis-Hastings, etc. Currently, only the default stepping-out slice sampler is fully implemented and tested.

## (Optional) create a `Starts` object.

The `Starts` S4 class has the starting values of an MCMC chain. Usually, the user does not need to worry about it, as the unspecified starting values are automatically generated for a given dataset and design with `generate_starts` inside the constructor of `Chain` class. However, the user may wish to modify individual slots. For more information, type `help("Starts-class")` and be sure to read the vignette on the hierarchical model.

## Create a `Chain` object.

The `Chain` class plays the role of an environment or workspace. It stores all the information in your `Scenario`, `Configs`, and `Starts` objects, in addition to Monte Carlo output and results. There are many, many S4 slots. For details on the slots, type `help("Chain-class")` and be sure to read the hierarchical model vignette. For help on how to create `Chain` objects, type `help("Chain")`.

With only a `Scenario` object, you can create a `Chain` object with 

```{r, eval = F}
chain = Chain(scenario)
```

If you have `Configs` and/or `Starts` objects, you can pass them in as well.


```{r, eval = F}
chain = Chain(scenario, configs, starts)
```

As an example, here is the `Chain` created from the `paschold` scenario visited earlier.

```{r}
chain = Chain(paschold)
str(chain)
```

You can recover the scenario, configuration, or starting values of a `Chain` object with the `Scenario`, `Configs`, and `Starts` objects. For example,

```{r}
scenario = Scenario(chain)
configs = Configs(chain)
starts = Starts(chain)
str(scenario)
str(configs)
str(starts)
```

Note that the unspecified starting values were automatically generated in the construction of the `Chain` object.

## Call `fbseq` on the `Chain` object.

The `fbseq` function actually runs the MCMC algorithm to fit the model and calculate posterior probabilities of interest. It takes a single `Chain` object as an argument, and if the `additional_chains` argument is 0, outputs another `Chain` object with posterior means and means of squares of parameters, estimated posterior probabilities of interest, and updated starting values.

```{r, eval = F}
out = fbseq(chain, additional_chains = 0)
```

The starting values of `out` are the final parameter samples of the previous MCMC. The upshot is that calling `fbseq` on `out` will resume the MCMC where it left off.

```{r, eval = F}
continuation = fbseq(out, additional_chains = 0)
```

You can even run the MCMC indefinitely and save your work at after every attempt.

```{r, eval = F}
repeat{
  chain = fbseq(chain, additional_chains = 0)
  saveRDS(chain, "chain.rds")
}
```

If the `additional_chains` argument is greater than 0, an additional `additional_chains` MCMC chains will be run after the first one, and the output object from `fbseq` will a list of the total `1 + additional_chains` run. This is useful for computing Gelman-Rubin potential scale reduction factors with the `psrf` function to assess convergence.

```{r, eval = F}
out = fbseq(chain, additional_chains = 3)
psrf(out)
```


## Inspect the output.

No sample output is shipped with this package because output  `Chain` objects are is usually large, in the tens of megabytes at least. However, all the functions to extract output are easy one-liners. Let `obj` be a either single `Chain` object or a list of chain objects returned by `fbseq()`.

|------------------------------------|----------|--------------------------------------------------| 
| `probs(obj)`   |	|  Estimated gene-specific posterior probabilities of each logical proposition specified in `Scenario` | 
| `effect_sizes(obj)`    |	| Estimated gene-specific effect sizes for each logical proposition. For example, if the proposition is "$2\beta_{2, g} - \beta_{4, g} > 1$ and $2\beta_{3, g} - \beta_{4, g} > 0.5$", then the effect size is $\min \left (2\beta_{2, g} - \beta_{4, g} - 1, \ 2\beta_{3, g} - \beta_{4, g} - 0.5 \right )^+$, where $(\cdots)^+$ denote the positive part of an expression. | 
| `estimates(obj, level)`  |	|  Posterior means and credible intervals (of level `level`) for all parameters. Note: to avoid taking up too much memory, the credible intervals are computed using the posterior means and variances of parameters, not quantiles of actual parameter samples. The results are approximate. | 
|`mcmc_samples(obj)` |	$\qquad$ | Monte Carlo samples of returned parameters selected in `Configs` | 
| `volcano(obj)`   |	| `ggplot2` plot of posterior probabilities vs effect sizes for each proposition. | 
| `DIC(obj)`   |	| Returns the deviance information criterion (DIC) and effective number of model parameters [@bda], along with the actual number of model parameters. | 

# References
